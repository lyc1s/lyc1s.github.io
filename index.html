<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/w3css/3/w3.css">
<body>

<div style="padding-top:20px;padding-bottom:20px">
  <h1 style="text-align: center">CSE 168 Final Project </h1>
  <p style="text-align: center">Ronald Baldonado and Lucas Hwang</p>
</div>

<div>
  <h4 style="text-align: center"> <strong>Proposal: Homogeneous Volume Rendering for Subsurface Scattering</strong></h4>
  <p>For our project we plan to implement subsurface scattering through volumetric path tracing through a homogeneous volume. 
    As such, our project will be an extension of the path tracer to handle these new features. If there is time, then the path 
    tracer will be used to create a rendered image worthy for submission into a rendering competition. As volumetric rendering 
    requires entering tracing light rays through different media, transmission and full support for a BSDF are necessary. 
    Our BSDF implementation will follow the guidelines presented by the original GGX paper and will consist of our existing GGX 
    BRDF implementation, which we have been using for past homeworks, as well as an ideal BTDF implementation which we have written 
    specifically for this project. At each intersection, we will use the Fresnel term to probabilistically decide whether or not 
    we should sample according to the BRDF or BTDF. This will prevent our path tracer from growing at an exponential rate as otherwise 
    we would be shooting two rays at each intersection, one for reflection and one for refraction. With the addition of the BTDF we 
    will have effectively handled ray transmission and ray reflection thereby implementing a BSDF. Additionally we will model subsurface 
    scattering interactions by using volumetric rendering techniques whenever we enter an object. For these techniques we are following
    the closed tracking outline provided by the SIGGRAPH 2017 Course paper. We have rendered a variety of test
    images to show both our progress and final implementation.
    </p>
  
  <h5> <strong>Implementing the BTDF</strong></h5>
  <p> The first step in implementing our BSDF was to implement ray transmission through a material such as glass. In order to do this, 
    we implemented a BTDF using ideal refraction in order to generate our refracted ray. For our scenes we defined materials as either
    transmissive or non-transmissive, with all transmissive materials subject to both refraction and reflection. This
    is opposed non-transmissive materials which only handled surface reflection. We used the Fresnel reflection coefficient to decide
    between refraction and reflection at each intersection on a transmissive material. Direct lighting for transmissive materials is
    handled using either the GGX BTDF or GGX BRDF at each boundary depending on if the ray refracts or reflects. In both cases we generate a sample and test to see if it hits any
    of the lights within the scene. If the sample intersects with the light and is not occuluded, we use the respective BTDF or BRDF
    in order to add radiance due to direct lighting. Our BTDF implemenation test images are displayed 
    below:
  </p>
  <img src="btdf_dragon.PNG" alt="Dragon BTDF">
  <img src="btdf_cornell.PNG" alt="Cornell BTDF">
  <img src="btdf_mis.PNG" alt="MIS BTDF">
  
   <h5> <strong>Implementing Volumetric Rendering</strong></h5>
   <p> The second step to implementing our BSDF was to implement the aspects of volumetric rendering outlined in the SIGGRAPH course
    paper. We define absorption and scattering coefficients in our tester file and sum those together in order to get our extinction
     coefficient. This extinction coefficient is used to calculate transmittance, representing the overall loss of radiance, as we 
     travel through the medium. Transmittance is multiplied into our throughput at each intersection with free distance t being
     passed in as a parameter. Rather than estimating all contributions due to scattering and emission at each point while stepping 
     through a medium, we use Russian Roulette in order to choose which event to sample. The material's emission values are defined in
     the tester file and we return this value when encountering an emission event. In the case of a scattering event, we use an isotropic
     phase function in order to sample the uniform sphere and generate a random direction to scatter in. This scattering event represents
     the in-scattering property as the out-scattering property has been dealt with in transmittance. With these features, we have
     implemented all four aspects of volumetric rendering (absorption, emission, in-scattering, out-scattering).
  </p>
</div>
  
 

<div>
  
  <p>Default Scene</p>
  <img src="default_scene.PNG" alt="Default Scene">
  <p>BTDF Implementation with Sampling based on Fresnel Reflection Coefficient</p>
  <img src="btdf_implementation_fresnel.PNG" alt="BTDF Fresnel">
  <p>BTDF with Attenuation</p>
  <img src="btdf_implementation_attenuation.PNG" alt="BTDF Attenuation">
</div>

</body>
</html>
